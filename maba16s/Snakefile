import time
import os
from shutil import copy2
import pathlib
import pandas as pd

configfile: "config/config.yaml"


OUTDIR = config['parameters']['outdir'] + "/"
configfile: OUTDIR + "config/config_good_samples.yaml"
SAMPLES = config['GOODSAMPLES']



onstart:
    print("This is MABA16S")
    time.sleep(1)

    # copy the config file to output dir
    pathlib.Path(OUTDIR).mkdir(parents=True, exist_ok=True)
    copy2('config/config.yaml', OUTDIR)
    for i in SAMPLES.items():
        print(i[0], '\t', i[1])
    print(f'output directory is: {OUTDIR}')

onerror:
    print(f"these were the samples: {SAMPLES}")
    print("error has occured")


localrules: all, download_kraken2_db, combinereads

rule all:
    input:
        #expand(OUTDIR + 'BLAST/{sample}', sample=SAMPLES),
        #expand(OUTDIR + "reports/{sample}.xlsx", sample=SAMPLES),
        expand(OUTDIR + "sankeys/{sample}_sankey.html", sample=SAMPLES)


rule download_kraken2_db:
    output:
        "db/silva"
    threads: 1
    conda:
        "envs/kraken2.yaml"
    params:
        "db/silva"
    shell:
        "kraken2-build --db {params} --special silva"


rule build_blast_db:
    input:
        "db/silva/data/SILVA_138.1_SSURef_NR99_tax_silva.fasta"
    output:
        directory("db/blastDB")
    threads: 1
    conda:
        "envs/blast.yaml"
    log:
        "log/blastbuild_db.log"
    params:
        "db/blastDB"
    shell:
        "makeblastdb -in {input} -dbtype nucl -out {output}/blastDB 2> {log}"


rule combinereads:
    input:
        lambda wildcards: SAMPLES[wildcards.sample]
    output:
        temp(OUTDIR + "reads/{sample}.fastq.gz")
    threads: 1
    shell:
        "cat {input}/*fastq* > {output}"

rule filter_read_length:
    input:
        rules.combinereads.output
    output:
        OUTDIR + "filtered_reads/{sample}.fastq.gz"
    conda:
        "envs/filter_reads.yaml"
    threads: 1
    params:
        min_length = 1200
    log: 
        OUTDIR + "log/filter_read_length/{sample}.log"
    shell: 
        "filtlong --min_length {params.min_length} {input} | gzip > {output}  2> {log}"

rule kraken2:
    input:
        reads = rules.filter_read_length.output,
        db = rules.download_kraken2_db.output
    output:
        report = OUTDIR + "kraken2/{sample}/krakenreport.txt",
        out = OUTDIR + "kraken2/{sample}/output.txt"
    threads: 4
    conda:
        "envs/kraken2.yaml"
    log:
        OUTDIR + "log/{sample}/kraken2_main.txt.txt"
    shell:
        "kraken2 --db {input.db} -t {threads} "
        "--report {output.report} {input.reads} > {output.out} "


rule strip_genera:
    input:
        rules.kraken2.output.report
    output:
        OUTDIR + "kraken2/{sample}/krakenreport_filtered.txt"
    params:
        reads_cutoff_genus = 50
    log:
        OUTDIR + "log/{sample}/stripgenera.txt"
    shell:
        '''awk '$4 == "G" {{print $0}}' {input} | awk '$2 > {params.reads_cutoff_genus} {{print $0}}' > {output} 2> {log}'''


rule genus_read_extract:
    input:
        report = OUTDIR + "kraken2/{sample}/krakenreport_filtered.txt",
        krakenfile = rules.kraken2.output.out,
        fastq = rules.filter_read_length.output
    output:
        temp(directory(OUTDIR + "kraken2/{sample}/genus"))
    threads:
        1
    conda:
        "envs/kraken2.yaml"
    log:
        OUTDIR + "log/{sample}/genusreadextract.log"
    shell:
        '''
        python scripts/krakenextract.py {input.report} {input.krakenfile} {input.fastq} {output}
        '''


rule map_genera:
    input:
        readdir = rules.genus_read_extract.output,
        ref = "db/silva/data/SILVA_138.1_SSURef_NR99_tax_silva.fasta"
    output:
        directory(OUTDIR + 'kraken2consensus/{sample}/')
    threads: 1
    conda:
        "envs/minimapsamtools.yaml"
    log:
        OUTDIR + "log/{sample}/map_genera.log"
    shell:
        "python scripts/aligner.py {input.readdir} {input.ref} {output} 2> {log}"


rule blast_consensus_genera:
    input:
        db = rules.build_blast_db.output,
        fastas = rules.map_genera.output
    output:
        directory(OUTDIR + 'BLAST/{sample}')
    threads:
        4
    conda:
        "envs/blast.yaml"
    log:
        OUTDIR + 'log/{sample}/blast_consensus_genera.log'
    shell:
        "python scripts/blast_consensus.py {input.fastas}/fastas/ {threads} {input.db} {output} 2> {log} "


rule generate_reports:
    input:
        blast = rules.blast_consensus_genera.output,
        readcount = rules.strip_genera.output
    output:
        OUTDIR + "reports/{sample}.xlsx"
    threads: 1
    conda:
        "envs/kraken2.yaml" # this env has pandas
    log:
        OUTDIR + "log/{sample}/report.log"
    shell:
        "python scripts/generate_reports.py {input.blast} {output} {input.readcount} 2> {log}"

rule make_sankeys:
    input:
        rules.generate_reports.output
    output:
        OUTDIR + "sankeys/{sample}_sankey.html"
    threads: 1 
    conda:
        "envs/plotly.yaml"
    log:
        OUTDIR + "log/make_sankey/{sample}.log"
    shell:
        "python scripts/sankey_report.py {input} {output}"